#!/bin/bash

# ðŸš€ AIå…«å¦è¿åŠ¿å°ç¨‹åº - è…¾è®¯äº‘DockerçŽ¯å¢ƒä¸€é”®éƒ¨ç½²è„šæœ¬ v2025
# é€‚ç”¨äºŽ: è…¾è®¯äº‘DockerçŽ¯å¢ƒ(è½»é‡åº”ç”¨æœåŠ¡å™¨/å®¹å™¨å®žä¾‹)
# å‰æ: DockerçŽ¯å¢ƒå·²é¢„è£…
# ä½¿ç”¨æ–¹æ³•: ./scripts/deploy-tencent-docker-2025.sh

set -e

# ===================== é…ç½®å‚æ•° =====================
PROJECT_NAME="bagua-ai"
PROJECT_DIR="/app/${PROJECT_NAME}"
BACKUP_DIR="/backup"
LOG_DIR="/var/log/${PROJECT_NAME}"
LOG_FILE="${LOG_DIR}/deploy.log"

# ç½‘ç»œé…ç½®
APP_PORT="8080"
FRONTEND_PORT="3000"
DB_PORT="3306"
REDIS_PORT="6379"
NGINX_HTTP_PORT="80"
NGINX_HTTPS_PORT="443"

# ç‰ˆæœ¬é…ç½®
DOCKER_COMPOSE_VERSION="2.24.1"

# ===================== é¢œè‰²è¾“å‡º =====================
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# ===================== æ—¥å¿—å‡½æ•° =====================
setup_logging() {
    if [ "$DRY_RUN" == "true" ]; then
        # æµ‹è¯•æ¨¡å¼ä½¿ç”¨å½“å‰ç›®å½•
        LOG_DIR="./logs"
        mkdir -p $LOG_DIR
        LOG_FILE="${LOG_DIR}/deploy_test.log"
    else
        # å®žé™…éƒ¨ç½²æ¨¡å¼ä½¿ç”¨ç³»ç»Ÿæ—¥å¿—ç›®å½•
        mkdir -p $LOG_DIR
    fi
    
    exec 1> >(tee -a $LOG_FILE)
    exec 2> >(tee -a $LOG_FILE >&2)
}

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] INFO:${NC} $1"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARN:${NC} $1"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1"
}

success() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] SUCCESS:${NC} $1"
}

step() {
    echo -e "\n${PURPLE}========================${NC}"
    echo -e "${PURPLE} $1${NC}"
    echo -e "${PURPLE}========================${NC}\n"
}

# ===================== çŽ¯å¢ƒæ£€æŸ¥ =====================
check_docker_environment() {
    step "æ£€æŸ¥è…¾è®¯äº‘DockerçŽ¯å¢ƒ"
    
    # æ£€æŸ¥Dockeræ˜¯å¦å¯ç”¨
    if ! command -v docker &> /dev/null; then
        error "Dockeræœªæ‰¾åˆ°ï¼è¯·ç¡®è®¤æ‚¨ä½¿ç”¨çš„æ˜¯è…¾è®¯äº‘DockerçŽ¯å¢ƒ"
        exit 1
    fi
    
    # æ£€æŸ¥DockeræœåŠ¡çŠ¶æ€
    if ! docker info &> /dev/null; then
        error "DockeræœåŠ¡æœªè¿è¡Œï¼Œå°è¯•å¯åŠ¨..."
        sudo systemctl start docker || service docker start
        sleep 5
        if ! docker info &> /dev/null; then
            error "DockeræœåŠ¡å¯åŠ¨å¤±è´¥"
            exit 1
        fi
    fi
    
    # æ£€æŸ¥Dockerç‰ˆæœ¬
    DOCKER_VERSION=$(docker --version)
    log "Dockerç‰ˆæœ¬: $DOCKER_VERSION"
    
    # æ£€æŸ¥Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        log "å®‰è£…Docker Compose..."
        sudo curl -L "https://github.com/docker/compose/releases/download/v${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
    else
        log "Docker Composeå·²å®‰è£…: $(docker-compose --version)"
    fi
    
    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
    MEMORY=$(free -m | awk 'NR==2{printf "%.0f", $2/1024}')
    DISK_AVAIL=$(df -BG / | awk 'NR==2{print $4}' | sed 's/G//')
    CPU_CORES=$(nproc)
    
    log "ç³»ç»Ÿèµ„æº:"
    log "  - å†…å­˜: ${MEMORY}GB"
    log "  - CPUæ ¸å¿ƒ: $CPU_CORES"
    log "  - å¯ç”¨ç£ç›˜: ${DISK_AVAIL}GB"
    
    # èµ„æºæ£€æŸ¥
    if [ "$MEMORY" -lt 2 ]; then
        warn "å†…å­˜è¾ƒå°‘(${MEMORY}GB)ï¼Œå»ºè®®è‡³å°‘2GB"
    fi
    
    if [ "$DISK_AVAIL" -lt 10 ]; then
        error "ç£ç›˜ç©ºé—´ä¸è¶³(${DISK_AVAIL}GB)ï¼Œéœ€è¦è‡³å°‘10GB"
        exit 1
    fi
    
    success "è…¾è®¯äº‘DockerçŽ¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# ===================== èŽ·å–ç”¨æˆ·ä¿¡æ¯ =====================
get_current_user() {
    if [ -n "$SUDO_USER" ]; then
        REAL_USER="$SUDO_USER"
    else
        REAL_USER="$(whoami)"
    fi
    log "å½“å‰ç”¨æˆ·: $REAL_USER"
}

# ===================== ç½‘ç»œé…ç½®æ£€æŸ¥ =====================
check_network() {
    step "æ£€æŸ¥ç½‘ç»œé…ç½®"
    
    # æ£€æŸ¥ç«¯å£å ç”¨
    check_port() {
        local port=$1
        local service=$2
        if netstat -tuln 2>/dev/null | grep -q ":$port "; then
            warn "ç«¯å£ $port å·²è¢«å ç”¨ï¼Œå¯èƒ½å½±å“ $service æœåŠ¡"
            netstat -tuln | grep ":$port "
        else
            log "ç«¯å£ $port å¯ç”¨ ($service)"
        fi
    }
    
    check_port $NGINX_HTTP_PORT "HTTP"
    check_port $NGINX_HTTPS_PORT "HTTPS"
    check_port $APP_PORT "åŽç«¯API"
    check_port $DB_PORT "MySQL"
    check_port $REDIS_PORT "Redis"
    
    # æ£€æŸ¥å¤–ç½‘è¿žæŽ¥
    if ping -c 1 8.8.8.8 &> /dev/null; then
        log "å¤–ç½‘è¿žæŽ¥æ­£å¸¸"
    else
        warn "å¤–ç½‘è¿žæŽ¥å¯èƒ½æœ‰é—®é¢˜ï¼Œå¯èƒ½å½±å“é•œåƒä¸‹è½½"
    fi
    
    success "ç½‘ç»œé…ç½®æ£€æŸ¥å®Œæˆ"
}

# ===================== é¡¹ç›®è®¾ç½® =====================
setup_project() {
    step "è®¾ç½®é¡¹ç›®çŽ¯å¢ƒ"
    
    # åˆ›å»ºé¡¹ç›®ç›®å½•
    sudo mkdir -p $PROJECT_DIR
    sudo mkdir -p $BACKUP_DIR
    sudo mkdir -p $LOG_DIR
    
    # å¦‚æžœé¡¹ç›®ç›®å½•å·²å­˜åœ¨ï¼Œåˆ›å»ºå¤‡ä»½
    if [ -d "$PROJECT_DIR" ] && [ "$(ls -A $PROJECT_DIR 2>/dev/null)" ]; then
        BACKUP_NAME="backup-$(date +%Y%m%d_%H%M%S)"
        log "å¤‡ä»½çŽ°æœ‰éƒ¨ç½²åˆ°: $BACKUP_DIR/$BACKUP_NAME"
        sudo cp -r $PROJECT_DIR $BACKUP_DIR/$BACKUP_NAME
        sudo rm -rf $PROJECT_DIR/*
    fi
    
    # å¤åˆ¶é¡¹ç›®æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
    if [ -f "$(pwd)/package.json" ] || [ -f "$(pwd)/pom.xml" ]; then
        log "å¤åˆ¶é¡¹ç›®æ–‡ä»¶åˆ° $PROJECT_DIR"
        sudo cp -r $(pwd)/* $PROJECT_DIR/
    else
        log "å½“å‰ç›®å½•éžé¡¹ç›®æ ¹ç›®å½•ï¼Œè¯·ç¡®ä¿åœ¨æ­£ç¡®ä½ç½®è¿è¡Œè„šæœ¬"
    fi
    
    # è®¾ç½®ç›®å½•æƒé™
    sudo chown -R $REAL_USER:$REAL_USER $PROJECT_DIR 2>/dev/null || true
    sudo chown -R $REAL_USER:$REAL_USER $BACKUP_DIR 2>/dev/null || true
    sudo chmod -R 755 $PROJECT_DIR
    
    success "é¡¹ç›®ç›®å½•è®¾ç½®å®Œæˆ: $PROJECT_DIR"
}

# ===================== çŽ¯å¢ƒå˜é‡é…ç½® =====================
setup_environment() {
    step "é…ç½®çŽ¯å¢ƒå˜é‡"
    
    # ç”Ÿæˆå®‰å…¨å¯†ç 
    MYSQL_ROOT_PASSWORD=$(openssl rand -base64 32)
    MYSQL_PASSWORD=$(openssl rand -base64 32)
    REDIS_PASSWORD=$(openssl rand -base64 32)
    JWT_SECRET=$(openssl rand -hex 64)
    ENCRYPTION_KEY=$(openssl rand -hex 32)
    
    # åˆ›å»ºçŽ¯å¢ƒé…ç½®æ–‡ä»¶
    cat > $PROJECT_DIR/.env.production << EOF
# ===================== åº”ç”¨é…ç½® =====================
NODE_ENV=production
APP_PORT=$APP_PORT
FRONTEND_PORT=$FRONTEND_PORT

# ===================== æ•°æ®åº“é…ç½® =====================
MYSQL_HOST=mysql
MYSQL_PORT=$DB_PORT
MYSQL_DATABASE=bagua_fortune
MYSQL_USERNAME=bagua_user
MYSQL_PASSWORD=$MYSQL_PASSWORD
MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD

# ===================== Redisé…ç½® =====================
REDIS_HOST=redis
REDIS_PORT=$REDIS_PORT
REDIS_PASSWORD=$REDIS_PASSWORD

# ===================== å®‰å…¨é…ç½® =====================
JWT_SECRET=$JWT_SECRET
ENCRYPTION_KEY=$ENCRYPTION_KEY

# ===================== å¾®ä¿¡å°ç¨‹åºé…ç½®ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼‰=====================
WECHAT_APP_ID=è¯·é…ç½®æ‚¨çš„å¾®ä¿¡AppID
WECHAT_APP_SECRET=è¯·é…ç½®æ‚¨çš„å¾®ä¿¡AppSecret

# ===================== AIé…ç½®ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼‰=====================
DEEPSEEK_API_KEY=è¯·é…ç½®æ‚¨çš„DeepSeek API Key
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions
DEEPSEEK_MODEL=deepseek-chat

# ===================== æ—¥å¿—é…ç½® =====================
LOG_LEVEL=info
LOG_DIR=$LOG_DIR

# ===================== è…¾è®¯äº‘DockerçŽ¯å¢ƒé…ç½® =====================
DOCKER_REGISTRY_MIRROR=mirror.ccs.tencentcloudcr.com
EOF
    
    # è®¾ç½®æ–‡ä»¶æƒé™
    chmod 600 $PROJECT_DIR/.env.production
    
    log "çŽ¯å¢ƒé…ç½®æ–‡ä»¶å·²åˆ›å»º: $PROJECT_DIR/.env.production"
    warn "è¯·ç¼–è¾‘çŽ¯å¢ƒé…ç½®æ–‡ä»¶ï¼Œè®¾ç½®å¾®ä¿¡å°ç¨‹åºå’ŒAIç›¸å…³é…ç½®"
    
    # åˆ›å»ºå¯†ç å¤‡ä»½æ–‡ä»¶
    cat > $PROJECT_DIR/.passwords.backup << EOF
# æ•°æ®åº“å¯†ç å¤‡ä»½ - è¯·å¦¥å–„ä¿ç®¡
MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD
MYSQL_PASSWORD=$MYSQL_PASSWORD
REDIS_PASSWORD=$REDIS_PASSWORD
JWT_SECRET=$JWT_SECRET
ENCRYPTION_KEY=$ENCRYPTION_KEY
EOF
    chmod 600 $PROJECT_DIR/.passwords.backup
    log "å¯†ç å¤‡ä»½æ–‡ä»¶å·²åˆ›å»º: $PROJECT_DIR/.passwords.backup"
}

# ===================== Dockeré…ç½®ä¼˜åŒ– =====================
optimize_docker() {
    step "ä¼˜åŒ–Dockeré…ç½®"
    
    # æ£€æŸ¥Dockeré…ç½®ç›®å½•
    sudo mkdir -p /etc/docker
    
    # ä¼˜åŒ–Dockeré…ç½®ï¼ˆé’ˆå¯¹è…¾è®¯äº‘çŽ¯å¢ƒï¼‰
    cat << 'EOF' | sudo tee /etc/docker/daemon.json > /dev/null
{
    "registry-mirrors": [
        "https://mirror.ccs.tencentcloudcr.com",
        "https://ccr.ccs.tencentcloudcr.com"
    ],
    "log-driver": "json-file",
    "log-opts": {
        "max-size": "100m",
        "max-file": "3"
    },
    "storage-driver": "overlay2",
    "max-concurrent-downloads": 10,
    "max-concurrent-uploads": 5
}
EOF
    
    # é‡å¯DockeræœåŠ¡
    sudo systemctl restart docker 2>/dev/null || sudo service docker restart
    sleep 5
    
    # éªŒè¯Dockeré…ç½®
    if docker info | grep -q "Registry Mirrors"; then
        success "Dockeré•œåƒåŠ é€Ÿé…ç½®æˆåŠŸ"
    else
        warn "Dockeré•œåƒåŠ é€Ÿé…ç½®å¯èƒ½æœªç”Ÿæ•ˆ"
    fi
}

# ===================== Docker Composeé…ç½® =====================
create_docker_compose() {
    step "åˆ›å»ºDocker Composeé…ç½®"
    
    cat > $PROJECT_DIR/docker-compose.yml << 'EOF'
version: '3.8'

services:
  # ===================== æ•°æ®åº“æœåŠ¡ =====================
  mysql:
    image: mysql:8.0
    container_name: bagua-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USERNAME}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      TZ: Asia/Shanghai
    ports:
      - "${MYSQL_PORT}:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./sql:/docker-entrypoint-initdb.d:ro
    networks:
      - bagua-network
    command: --default-authentication-plugin=mysql_native_password
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      interval: 30s

  # ===================== RedisæœåŠ¡ =====================
  redis:
    image: redis:7-alpine
    container_name: bagua-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    environment:
      TZ: Asia/Shanghai
    ports:
      - "${REDIS_PORT}:6379"
    volumes:
      - redis_data:/data
    networks:
      - bagua-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      timeout: 10s
      retries: 5
      interval: 30s

  # ===================== åŽç«¯æœåŠ¡ =====================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: bagua-backend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - TZ=Asia/Shanghai
      - MYSQL_HOST=mysql
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USERNAME=${MYSQL_USERNAME}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - WECHAT_APP_ID=${WECHAT_APP_ID}
      - WECHAT_APP_SECRET=${WECHAT_APP_SECRET}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DEEPSEEK_API_URL=${DEEPSEEK_API_URL}
      - DEEPSEEK_MODEL=${DEEPSEEK_MODEL}
    ports:
      - "${APP_PORT}:8080"
    volumes:
      - ./logs:/app/logs
    networks:
      - bagua-network
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ===================== å‰ç«¯æœåŠ¡ =====================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: bagua-frontend
    restart: unless-stopped
    environment:
      TZ: Asia/Shanghai
    ports:
      - "${FRONTEND_PORT}:80"
    networks:
      - bagua-network
    depends_on:
      - backend

  # ===================== Nginxåå‘ä»£ç† =====================
  nginx:
    image: nginx:alpine
    container_name: bagua-nginx
    restart: unless-stopped
    environment:
      TZ: Asia/Shanghai
    ports:
      - "${NGINX_HTTP_PORT}:80"
      - "${NGINX_HTTPS_PORT}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    networks:
      - bagua-network
    depends_on:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      timeout: 10s
      retries: 3
      interval: 30s

# ===================== æ•°æ®å· =====================
volumes:
  mysql_data:
    driver: local
  redis_data:
    driver: local

# ===================== ç½‘ç»œ =====================
networks:
  bagua-network:
    driver: bridge
EOF
    
    success "Docker Composeé…ç½®å·²åˆ›å»º"
}

# ===================== Nginxé…ç½® =====================
create_nginx_config() {
    step "åˆ›å»ºNginxé…ç½®"
    
    mkdir -p $PROJECT_DIR/nginx/conf.d
    mkdir -p $PROJECT_DIR/nginx/ssl
    mkdir -p $PROJECT_DIR/logs/nginx
    
    # ä¸»é…ç½®æ–‡ä»¶
    cat > $PROJECT_DIR/nginx/nginx.conf << 'EOF'
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    
    # åŸºæœ¬è®¾ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;
    server_tokens off;
    
    # GzipåŽ‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # åŒ…å«ç«™ç‚¹é…ç½®
    include /etc/nginx/conf.d/*.conf;
}
EOF
    
    # ç«™ç‚¹é…ç½®æ–‡ä»¶
    cat > $PROJECT_DIR/nginx/conf.d/bagua-ai.conf << 'EOF'
server {
    listen 80;
    server_name _;
    
    # å®‰å…¨å¤´éƒ¨
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header X-Content-Type-Options "nosniff" always;
    
    # åŽç«¯APIä»£ç†
    location /api/ {
        proxy_pass http://backend:8080/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¶…æ—¶è®¾ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # ç¼“å†²è®¾ç½®
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }
    
    # é™æ€æ–‡ä»¶ä»£ç†
    location / {
        proxy_pass http://frontend:80;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    # å¥åº·æ£€æŸ¥
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    # é˜»æ­¢è®¿é—®æ•æ„Ÿæ–‡ä»¶
    location ~ /\. {
        deny all;
        access_log off;
        log_not_found off;
    }
}
EOF
    
    success "Nginxé…ç½®å·²åˆ›å»º"
}

# ===================== ç®¡ç†è„šæœ¬ =====================
create_management_scripts() {
    step "åˆ›å»ºç®¡ç†è„šæœ¬"
    
    # å¯åŠ¨è„šæœ¬
    cat > $PROJECT_DIR/start.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ å¯åŠ¨AIå…«å¦è¿åŠ¿å°ç¨‹åº..."
docker-compose --env-file .env.production up -d
echo "âœ… å¯åŠ¨å®Œæˆï¼è®¿é—®åœ°å€: http://$(curl -s ifconfig.me 2>/dev/null || echo 'localhost')"
EOF
    
    # åœæ­¢è„šæœ¬
    cat > $PROJECT_DIR/stop.sh << 'EOF'
#!/bin/bash
echo "ðŸ›‘ åœæ­¢AIå…«å¦è¿åŠ¿å°ç¨‹åº..."
docker-compose down
echo "âœ… æœåŠ¡å·²åœæ­¢"
EOF
    
    # é‡å¯è„šæœ¬
    cat > $PROJECT_DIR/restart.sh << 'EOF'
#!/bin/bash
echo "ðŸ”„ é‡å¯AIå…«å¦è¿åŠ¿å°ç¨‹åº..."
docker-compose down
docker-compose --env-file .env.production up -d
echo "âœ… é‡å¯å®Œæˆï¼"
EOF
    
    # æ—¥å¿—æŸ¥çœ‹è„šæœ¬
    cat > $PROJECT_DIR/logs.sh << 'EOF'
#!/bin/bash
if [ -z "$1" ]; then
    echo "ðŸ“‹ æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—..."
    docker-compose logs -f --tail=100
else
    echo "ðŸ“‹ æŸ¥çœ‹ $1 æœåŠ¡æ—¥å¿—..."
    docker-compose logs -f --tail=100 $1
fi
EOF
    
    # çŠ¶æ€æ£€æŸ¥è„šæœ¬
    cat > $PROJECT_DIR/status.sh << 'EOF'
#!/bin/bash
echo "ðŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
echo ""
echo "=== å®¹å™¨çŠ¶æ€ ==="
docker-compose ps
echo ""
echo "=== å¥åº·æ£€æŸ¥ ==="
curl -s http://localhost/health >/dev/null && echo "âœ… Nginx: å¥åº·" || echo "âŒ Nginx: å¼‚å¸¸"
curl -s http://localhost:8080/health >/dev/null && echo "âœ… åŽç«¯: å¥åº·" || echo "âŒ åŽç«¯: å¼‚å¸¸"
echo ""
echo "=== èµ„æºä½¿ç”¨ ==="
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
EOF
    
    # æ›´æ–°è„šæœ¬
    cat > $PROJECT_DIR/update.sh << 'EOF'
#!/bin/bash
echo "ðŸ”„ æ›´æ–°åº”ç”¨..."
git pull
docker-compose build --no-cache
docker-compose down
docker-compose --env-file .env.production up -d
echo "âœ… æ›´æ–°å®Œæˆï¼"
EOF
    
    # å¤‡ä»½è„šæœ¬
    cat > $PROJECT_DIR/backup.sh << 'EOF'
#!/bin/bash
BACKUP_NAME="backup-$(date +%Y%m%d_%H%M%S)"
echo "ðŸ’¾ åˆ›å»ºå¤‡ä»½: $BACKUP_NAME"
mkdir -p /backup
docker exec bagua-mysql mysqldump -u root -p${MYSQL_ROOT_PASSWORD} bagua_fortune > /backup/${BACKUP_NAME}_mysql.sql
tar -czf /backup/${BACKUP_NAME}_app.tar.gz /app/bagua-ai --exclude=/app/bagua-ai/logs
echo "âœ… å¤‡ä»½å®Œæˆ: /backup/${BACKUP_NAME}"
EOF
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    chmod +x $PROJECT_DIR/*.sh
    
    success "ç®¡ç†è„šæœ¬å·²åˆ›å»º"
}

# ===================== é¢„æ‹‰å–é•œåƒ =====================
pull_images() {
    step "é¢„æ‹‰å–Dockeré•œåƒ"
    
    log "æ‹‰å–åŸºç¡€é•œåƒ..."
    docker pull mysql:8.0
    docker pull redis:7-alpine  
    docker pull nginx:alpine
    docker pull node:18-alpine
    docker pull openjdk:17-jdk-slim
    
    success "é•œåƒæ‹‰å–å®Œæˆ"
}

# ===================== éƒ¨ç½²åº”ç”¨ =====================
deploy_application() {
    step "éƒ¨ç½²åº”ç”¨"
    
    cd $PROJECT_DIR
    
    log "æž„å»ºå¹¶å¯åŠ¨æœåŠ¡..."
    docker-compose --env-file .env.production up -d --build
    
    log "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 30
    
    # å¥åº·æ£€æŸ¥
    local max_attempts=12
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        log "å¥åº·æ£€æŸ¥ (${attempt}/${max_attempts})..."
        
        if curl -sf http://localhost/health >/dev/null 2>&1; then
            success "åº”ç”¨éƒ¨ç½²æˆåŠŸï¼"
            return 0
        fi
        
        log "ç­‰å¾…æœåŠ¡å¯åŠ¨... (${attempt}/${max_attempts})"
        sleep 10
        ((attempt++))
    done
    
    error "åº”ç”¨å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
    docker-compose logs
    return 1
}

# ===================== æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯ =====================
show_deployment_info() {
    step "éƒ¨ç½²å®Œæˆ"
    
    # èŽ·å–å¤–ç½‘IP
    PUBLIC_IP=$(curl -s ifconfig.me 2>/dev/null || curl -s icanhazip.com 2>/dev/null || echo "localhost")
    
    echo -e "${CYAN}ðŸŽ‰ AIå…«å¦è¿åŠ¿å°ç¨‹åºéƒ¨ç½²æˆåŠŸï¼${NC}\n"
    
    echo -e "${GREEN}ðŸ“ è®¿é—®ä¿¡æ¯:${NC}"
    echo -e "  ðŸŒ åº”ç”¨åœ°å€: http://${PUBLIC_IP}"
    echo -e "  ðŸ“Š ç®¡ç†åœ°å€: http://${PUBLIC_IP}:${APP_PORT}/health"
    
    echo -e "\n${GREEN}ðŸ“ é¡¹ç›®ç›®å½•:${NC} $PROJECT_DIR"
    
    echo -e "\n${GREEN}ðŸ› ï¸ ç®¡ç†å‘½ä»¤:${NC}"
    echo -e "  å¯åŠ¨æœåŠ¡: cd $PROJECT_DIR && ./start.sh"
    echo -e "  åœæ­¢æœåŠ¡: cd $PROJECT_DIR && ./stop.sh"
    echo -e "  é‡å¯æœåŠ¡: cd $PROJECT_DIR && ./restart.sh"
    echo -e "  æŸ¥çœ‹æ—¥å¿—: cd $PROJECT_DIR && ./logs.sh"
    echo -e "  æ£€æŸ¥çŠ¶æ€: cd $PROJECT_DIR && ./status.sh"
    echo -e "  åº”ç”¨æ›´æ–°: cd $PROJECT_DIR && ./update.sh"
    echo -e "  æ•°æ®å¤‡ä»½: cd $PROJECT_DIR && ./backup.sh"
    
    echo -e "\n${YELLOW}âš ï¸ é‡è¦æé†’:${NC}"
    echo -e "  1. è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶: $PROJECT_DIR/.env.production"
    echo -e "  2. è®¾ç½®å¾®ä¿¡å°ç¨‹åºAppIDå’ŒAppSecret"
    echo -e "  3. é…ç½®DeepSeek API Key"
    echo -e "  4. å¯†ç å¤‡ä»½æ–‡ä»¶: $PROJECT_DIR/.passwords.backup"
    
    echo -e "\n${GREEN}ðŸ“‹ æœåŠ¡çŠ¶æ€:${NC}"
    cd $PROJECT_DIR && ./status.sh
}

# ===================== æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ =====================
create_database_init_scripts() {
    step "åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬"
    
    # åˆ›å»ºSQLç›®å½•
    mkdir -p $PROJECT_DIR/sql
    
    # å¤åˆ¶æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
    if [ -f "$(pwd)/complete-database-init.sql" ]; then
        log "å¤åˆ¶æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬"
        cp $(pwd)/complete-database-init.sql $PROJECT_DIR/sql/01-init-schema.sql
        chmod 644 $PROJECT_DIR/sql/01-init-schema.sql
    else
        warn "æœªæ‰¾åˆ°æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ï¼Œå°†åˆ›å»ºåŸºæœ¬ç»“æž„"
        
        # åˆ›å»ºåŸºæœ¬æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
        cat > $PROJECT_DIR/sql/01-init-schema.sql << 'EOF'
-- å…«å¦AIé¡¹ç›®æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
-- æ‰§è¡Œæ—¶é—´: $(date +%Y-%m-%d)
-- æ•°æ®åº“: MySQL 8.0+

-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS `fortune_db` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

USE `fortune_db`;

-- ç”¨æˆ·è¡¨
CREATE TABLE IF NOT EXISTS `t_users` (
    `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ç”¨æˆ·ID',
    `openid` VARCHAR(100) UNIQUE NOT NULL COMMENT 'å¾®ä¿¡openid',
    `nickname` VARCHAR(50) COMMENT 'æ˜µç§°',
    `avatar_url` VARCHAR(255) COMMENT 'å¤´åƒURL',
    `phone` VARCHAR(20) COMMENT 'æ‰‹æœºå·',
    `vip_level` INT DEFAULT 0 COMMENT 'VIPç­‰çº§ï¼š0-æ™®é€šç”¨æˆ·ï¼Œ1-æœˆåº¦VIPï¼Œ2-å¹´åº¦VIP',
    `vip_expire_time` DATETIME COMMENT 'VIPè¿‡æœŸæ—¶é—´',
    `created_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    `updated_time` DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    `deleted` TINYINT DEFAULT 0 COMMENT 'åˆ é™¤æ ‡è®°ï¼š0-æœªåˆ é™¤ï¼Œ1-å·²åˆ é™¤',
    INDEX idx_openid (openid),
    INDEX idx_created_time (created_time),
    INDEX idx_vip_level (vip_level)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='ç”¨æˆ·è¡¨';

-- å‘½ç†è®°å½•è¡¨
CREATE TABLE IF NOT EXISTS `t_fortune_record` (
    `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'è®°å½•ID',
    `user_id` BIGINT NOT NULL COMMENT 'ç”¨æˆ·ID',
    `name` VARCHAR(50) NOT NULL COMMENT 'å§“å',
    `gender` TINYINT NOT NULL COMMENT 'æ€§åˆ«ï¼š1-ç”·ï¼Œ2-å¥³',
    `birth_year` INT NOT NULL COMMENT 'å‡ºç”Ÿå¹´',
    `birth_month` INT NOT NULL COMMENT 'å‡ºç”Ÿæœˆ',
    `birth_day` INT NOT NULL COMMENT 'å‡ºç”Ÿæ—¥',
    `birth_hour` INT COMMENT 'å‡ºç”Ÿæ—¶è¾°',
    `lunar_year` INT COMMENT 'å†œåŽ†å¹´',
    `lunar_month` INT COMMENT 'å†œåŽ†æœˆ',
    `lunar_day` INT COMMENT 'å†œåŽ†æ—¥',
    `gan_zhi` VARCHAR(20) COMMENT 'å¹²æ”¯',
    `sheng_xiao` VARCHAR(10) COMMENT 'ç”Ÿè‚–',
    `wu_xing_analysis` TEXT COMMENT 'äº”è¡Œåˆ†æž',
    `ai_analysis` TEXT COMMENT 'AIåˆ†æžç»“æžœ',
    `name_analysis` TEXT COMMENT 'å§“ååˆ†æžç»“æžœ',
    `name_recommendations` JSON COMMENT 'AIæŽ¨èå§“å',
    `created_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    `updated_time` DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    `deleted` TINYINT DEFAULT 0 COMMENT 'åˆ é™¤æ ‡è®°ï¼š0-æœªåˆ é™¤ï¼Œ1-å·²åˆ é™¤',
    INDEX idx_user_id (user_id),
    INDEX idx_created_time (created_time),
    INDEX idx_birth_date (birth_year, birth_month, birth_day),
    INDEX idx_user_time (user_id, created_time DESC)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='å‘½ç†è®°å½•è¡¨';

-- æ’å…¥æµ‹è¯•ç”¨æˆ·
INSERT IGNORE INTO `t_users` (`openid`, `nickname`, `avatar_url`, `vip_level`) VALUES 
('test_openid_001', 'æµ‹è¯•ç”¨æˆ·1', 'https://example.com/avatar1.jpg', 0);

-- æ£€æŸ¥è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
SHOW TABLES;
EOF
    fi
    
    # åˆ›å»ºæ•°æ®åº“æ£€æŸ¥è„šæœ¬
    cat > $PROJECT_DIR/sql/02-check-schema.sql << 'EOF'
-- æ£€æŸ¥æ•°æ®åº“è¡¨æ˜¯å¦å­˜åœ¨
SELECT 
    table_name, 
    table_rows,
    CONCAT(ROUND(data_length / (1024 * 1024), 2), ' MB') as data_size,
    CONCAT(ROUND(index_length / (1024 * 1024), 2), ' MB') as index_size
FROM 
    information_schema.TABLES 
WHERE 
    table_schema = 'fortune_db';
EOF
    
    success "æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬å·²åˆ›å»º"
}

# ===================== ä¸»å‡½æ•° =====================
main() {
    echo -e "${CYAN}"
    echo -e "   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—"
    echo -e "  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘"
    echo -e "  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘"
    echo -e "  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘"
    echo -e "  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘"
    echo -e "  â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•"
    echo -e "${NC}"
    echo -e "  ðŸš€ è…¾è®¯äº‘DockerçŽ¯å¢ƒä¸€é”®éƒ¨ç½²è„šæœ¬ v2025\n"

    # å‚æ•°è§£æž
    DRY_RUN=false
    while getopts "hn" opt; do
        case $opt in
            h)
                show_help
                exit 0
                ;;
            n)
                DRY_RUN=true
                warn "ä»…æ‰§è¡Œæ£€æŸ¥ï¼Œä¸è¿›è¡Œå®žé™…éƒ¨ç½²"
                ;;
            *)
                error "æœªçŸ¥å‚æ•°: -$OPTARG"
                show_help
                exit 1
                ;;
        esac
    done

    # è®¾ç½®é”™è¯¯å¤„ç†
    trap 'error "è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…: $LOG_FILE"; exit 1' ERR

    # å¯åŠ¨æ—¥å¿—
    setup_logging
    log "å¼€å§‹éƒ¨ç½²AIå…«å¦è¿åŠ¿å°ç¨‹åºåˆ°è…¾è®¯äº‘DockerçŽ¯å¢ƒ..."
    log "å½“å‰ç›®å½•: $(pwd)"
    log "éƒ¨ç½²æ¨¡å¼: $([ "$DRY_RUN" == "true" ] && echo "æµ‹è¯•æ¨¡å¼" || echo "å®žé™…éƒ¨ç½²")"

    # èŽ·å–å½“å‰ç”¨æˆ·
    get_current_user

    # æ£€æŸ¥çŽ¯å¢ƒ
    check_docker_environment
    check_network

    # å¦‚æžœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œä¸è¿›è¡Œå®žé™…éƒ¨ç½²
    if [ "$DRY_RUN" == "true" ]; then
        success "æµ‹è¯•æ¨¡å¼æ£€æŸ¥å®Œæˆ"
        exit 0
    fi

    # è®¾ç½®é¡¹ç›®çŽ¯å¢ƒ
    setup_project
    setup_environment
    
    # åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
    create_database_init_scripts
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    optimize_docker
    create_docker_compose
    create_nginx_config
    create_management_scripts

    # é¢„æ‹‰å–é•œåƒ
    pull_images

    # éƒ¨ç½²åº”ç”¨
    deploy_application
    show_deployment_info

    success "éƒ¨ç½²å®Œæˆ!"
    exit 0
}

# é”™è¯¯å¤„ç†
trap 'error "éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: $LOG_FILE"' ERR

# è„šæœ¬å…¥å£
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi 